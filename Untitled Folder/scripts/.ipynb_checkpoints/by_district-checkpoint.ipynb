{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating file get_tehsil.csv\n",
      "0 UTTAR PRADESH Agra 9 146\n",
      "1 UTTAR PRADESH Aligarh 9 143\n",
      "2 UTTAR PRADESH Ambedkar Nagar 9 178\n",
      "3 UTTAR PRADESH Amethi 9 664\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException,TimeoutException\n",
    "import os\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import csv\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# Suponiendo monitor vertical de 1080px de alto x 1920 ancho\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"window-size=1080,1920\")\n",
    "options.add_argument(\"window-position=-1080,0\")\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://dilrmp.gov.in/faces/rptdistrictwisephysical/rptComputerizationOfLandRecord.xhtml?statecode=9\"\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = 'output'\n",
    "filename = \"get_district.csv\"\n",
    "output_path_dist = os.path.join(output_dir, filename)\n",
    "\n",
    "if not os.path.exists(output_path_dist):\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(url)\n",
    "    # Aplicar zoom 67% con JavaScript\n",
    "    zoom_level = 0.67\n",
    "    driver.execute_script(f\"document.body.style.zoom = '{zoom_level}'\")\n",
    "\n",
    "    # Obtener el elemento(footer) que nos molesta\n",
    "    elements = driver.find_elements(By.ID, 'footer')\n",
    "\n",
    "    if len(elements) > 0:\n",
    "        elem = elements[0]\n",
    "\n",
    "        # Ejecutar JS para eliminar ese elemento\n",
    "        driver.execute_script(\"\"\"\n",
    "        var element = arguments[0];\n",
    "        element.parentNode.removeChild(element);\n",
    "        \"\"\", elem)\n",
    "    else:\n",
    "        print(\"El elemento molestoso (footer) no existe\")\n",
    "\n",
    "    # # Aplicar zoom 67% con JavaScript\n",
    "    # zoom_level = 0.67\n",
    "    # driver.execute_script(f\"document.body.style.zoom = '{zoom_level}'\")\n",
    "\n",
    "    # Obtiene la URL actual de la página\n",
    "    url_actual = driver.current_url\n",
    "    # Analiza la URL\n",
    "    parsed_url = urlparse(url)\n",
    "    # Obtiene los parámetros de la URL\n",
    "    params = parse_qs(parsed_url.query)\n",
    "    # Obtiene el valor del parámetro 'statecode' (si existe)\n",
    "    statecode_value = params.get('statecode', [None])[0]\n",
    "\n",
    "    # Modificar el elemento Options para  mostrar toda la data en un solo plano\n",
    "    elem = driver.find_element(By.XPATH,'//*[@id=\"myform:compListTable_rppDD\"]/option[3]')\n",
    "    # Modificar html interno, texto y atributo\n",
    "    driver.execute_script(\"arguments[0].innerHTML = '10000'\", elem)\n",
    "    driver.execute_script(\"arguments[0].setAttribute('value', '10000')\", elem)\n",
    "    # driver.execute_script(\"arguments[0].click();\", elem)\n",
    "    elem.click()\n",
    "    sleep(1.35)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"myform\"]'))\n",
    "        )\n",
    "    data = []\n",
    "\n",
    "    state = driver.find_element(By.XPATH, '//*[@id=\"myform\"]/table/tbody/tr[1]/td/label')\n",
    "    state_name = state.text\n",
    "\n",
    "    districts = driver.find_elements(By.XPATH, '//*[@id=\"myform:compListTable_data\"]/tr/td[2]/a')\n",
    "    for district in districts:\n",
    "\n",
    "        links  = district.get_attribute(\"href\")\n",
    "\n",
    "        district_name = district.text\n",
    "\n",
    "        data.append({\"STATE\": state_name, \"DISTRICT\": district_name, \"URL_DISTRICT\": links, \"STATE_CODE\": statecode_value})\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        # Si no existe, la crea\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Guardamos el archivo Excel\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    df.to_csv(output_path_dist, index=False)\n",
    "\n",
    "    driver.quit()\n",
    "else:\n",
    "    print(f'Ya existe .\\{output_path_dist}')\n",
    "\n",
    "\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = \"output\"\n",
    "filename_teh = \"get_tehsil.csv\"\n",
    "output_path_teh = os.path.join(output_dir, filename_teh)\n",
    "\n",
    "# Verificar si el archivo principal existe\n",
    "if not os.path.exists(output_path_teh):\n",
    "    print(f\"Generating file {filename_teh}\")\n",
    "\n",
    "    # Crear un archivo CSV principal y escribir el encabezado\n",
    "    with open(output_path_teh, \"w\") as file:\n",
    "        file.write(\"STATE,DISTRICT,TEHSIL,URL_TEHSIL,STATE_CODE,DISTRICT_CODE,URL_DISTRICT\\n\")\n",
    "\n",
    "# Leer el archivo CSV de distritos\n",
    "df = pd.read_csv(output_path_dist)\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    state = row[\"STATE\"]\n",
    "    district = row[\"DISTRICT\"]\n",
    "    url_district = row[\"URL_DISTRICT\"]\n",
    "    statecode = row[\"STATE_CODE\"]\n",
    "\n",
    "\n",
    "    # Esto leera en cada iteración el mismo archivo al que se esta appendeando todo lo raspado\n",
    "    df_backup = pd.read_csv(output_path_teh)\n",
    "\n",
    "    # Verificar si la URL del distrito ya existe en el archivo de respaldo\n",
    "    if url_district in df_backup[\"URL_DISTRICT\"].values:\n",
    "        # print(f\"URL district {district} with code {statecode} already exists in backup. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(url_district)\n",
    "\n",
    "    # Capturar el código de distrito de la URL actual\n",
    "    parsed_url = urlparse(driver.current_url)\n",
    "    districtcode_value = parse_qs(parsed_url.query).get(\"districtcode\", [None])[0]\n",
    "\n",
    "    # Eliminar el elemento \"footer\" si existe\n",
    "    elements = driver.find_elements(By.ID, \"footer\")\n",
    "    if elements:\n",
    "        elem = elements[0]\n",
    "        driver.execute_script(\n",
    "            \"\"\"\n",
    "            var element = arguments[0];\n",
    "            element.parentNode.removeChild(element);\n",
    "            \"\"\",\n",
    "            elem,\n",
    "        )\n",
    "\n",
    "    # Modificar el campo de extracción\n",
    "    elem = driver.find_element(By.XPATH, '//*[@id=\"myform:compListTable_rppDD\"]/option[3]')\n",
    "    driver.execute_script(\"arguments[0].innerHTML = '10000'\", elem)\n",
    "    driver.execute_script(\"arguments[0].setAttribute('value', '10000')\", elem)\n",
    "    elem.click()\n",
    "    sleep(1.25)\n",
    "\n",
    "    # Esperar a que la página termine de cargar\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"myform\"]'))\n",
    "    )\n",
    "\n",
    "    # Obtener los tehsils y sus URL\n",
    "    tehsils = driver.find_elements(By.XPATH, '//*[@id=\"myform:compListTable_data\"]/tr/td[2]/a')\n",
    "    for tehsil in tehsils:\n",
    "        tehsil_name = tehsil.text\n",
    "        url_tehsil = tehsil.get_attribute(\"href\")\n",
    "\n",
    "        with open(output_path_teh, \"a\") as file:\n",
    "            file.write(\n",
    "                f\"{state},{district},{tehsil_name},{url_tehsil},{statecode},{districtcode_value},{url_district}\\n\"\n",
    "            )\n",
    "    print(index, state, district, statecode, districtcode_value)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "# Directorio de salida\n",
    "output_dir = \"output\"\n",
    "filename_villas = \"get_villas.csv\"\n",
    "output_path_villas = os.path.join(output_dir, filename_villas)\n",
    "\n",
    "# Verificar si el archivo principal existe\n",
    "if not os.path.exists(output_path_villas):\n",
    "    print(f\"Generating file {filename_villas}\")\n",
    "\n",
    "    # Crear un archivo CSV principal y escribir el encabezado\n",
    "    with open(output_path_villas, \"w\") as file:\n",
    "        file.write(\n",
    "            \"STATE,DISTRICT,TEHSIL,VILLAGE,TOTAL_OF_ROR,\"\n",
    "            \"TOTAL_OF_LAND_OWNER,ROR_DATA_ENTRY_AS_OF_P_S,AVAILABILITY_OF_ROR_DISTRIBUTION_P_S,\"\n",
    "            \"ROR_LINKAGE_WITH_AA_COMPLETED,ROR_LINKAGE_WITH_AA_ONGOING,\"\n",
    "            \"OF_LAND_OWNER_HOLDERS_WHOSE_ROR_L_W_A,\"\n",
    "            \"WHETHER_MUTATION_NOTICE_AND_MUTATION_WORKFLOW_A_C,\"\n",
    "            \"ISSUANCE_OF_DIGITALLY_SIGNED_ROR,ICT_CHANNEL_OF_DISTRIBUTION_OF_ROR,\"\n",
    "            \"STATUS_ENTRY_DATE,STATE_CODE,DISTRICT_CODE,TEHSIL_CODE,\"\n",
    "            \"URL_TEHSIL,URL_DISTRICT\\n\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Leer el archivo CSV de distritos\n",
    "df = pd.read_csv(output_path_teh)\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    state = row[\"STATE\"]\n",
    "    district = row[\"DISTRICT\"]\n",
    "    tehsil = row[\"TEHSIL\"]\n",
    "    url_tehsil = row[\"URL_TEHSIL\"]\n",
    "    url_district = row[\"URL_DISTRICT\"]\n",
    "    statecode = row[\"STATE_CODE\"]\n",
    "    districtcode = row[\"DISTRICT_CODE\"]\n",
    "\n",
    "    # Esto leera en cada iteración el mismo archivo al que se esta appendeando todo lo raspado\n",
    "    df_backup = pd.read_csv(output_path_villas)\n",
    "\n",
    "    # Verificar si la URL del distrito ya existe en el archivo de respaldo\n",
    "    if url_tehsil in df_backup[\"URL_TEHSIL\"].values:\n",
    "        # print(f\"URL district {district} with code {statecode} already exists in backup. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(url_tehsil)\n",
    "\n",
    "    # Capturar el código de distrito de la URL actual\n",
    "    parsed_url = urlparse(driver.current_url)\n",
    "    tehcode_value = parse_qs(parsed_url.query).get(\"tehcode\", [None])[0]\n",
    "\n",
    "    # Eliminar el elemento \"footer\" si existe\n",
    "    elements = driver.find_elements(By.ID, \"footer\")\n",
    "    if elements:\n",
    "        elem = elements[0]\n",
    "        driver.execute_script(\n",
    "            \"\"\"\n",
    "            var element = arguments[0];\n",
    "            element.parentNode.removeChild(element);\n",
    "            \"\"\",\n",
    "            elem,\n",
    "        )\n",
    "\n",
    "    # Modificar el campo de extracción\n",
    "    elem = driver.find_element(By.XPATH, '//*[@id=\"j_idt30:compList5_rppDD\"]/option[3]')\n",
    "    driver.execute_script(\"arguments[0].innerHTML = '10000'\", elem)\n",
    "    driver.execute_script(\"arguments[0].setAttribute('value', '10000')\", elem)\n",
    "    elem.click()\n",
    "    sleep(1.15)\n",
    "\n",
    "    # Esperar a que la página termine de cargar\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.ID, \"j_idt30\"))\n",
    "    )\n",
    "\n",
    "    # Localizar el elemento que contiene la tabla (por ejemplo, un tbody)\n",
    "    table_body = driver.find_elements(By.TAG_NAME, \"tbody\")[-1]\n",
    "    # Extraer las filas de la tabla\n",
    "    rows = table_body.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Escribir los datos en el archivo CSV\n",
    "    with open(output_path_villas, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Iterar sobre las filas y extraer los datos de cada columna\n",
    "        for row in rows:\n",
    "            # Extraer las celdas de la fila\n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            # Inicializar una lista para almacenar los datos de la fila\n",
    "            row_values = [\n",
    "                state,\n",
    "                district,\n",
    "                tehsil,\n",
    "                *[cell.text for cell in cells[1:]],  # Extraer texto de las celdas, omite la primera\n",
    "                statecode,\n",
    "                districtcode,\n",
    "                tehcode_value,\n",
    "                url_tehsil,\n",
    "                url_district\n",
    "            ]\n",
    "            writer.writerow(row_values)\n",
    "    print(index, state, district, statecode, districtcode_value)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

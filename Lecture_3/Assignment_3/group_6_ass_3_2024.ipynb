{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (1.2.6)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from pyreadstat) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ext-amardini\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../../_data/endes/2019/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_1, meta_1 = pyreadstat.read_sav(f\"{folder}{files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_2, meta_2 = pyreadstat.read_sav(f\"{folder}{files[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_3, meta_3 = pyreadstat.read_sav(f\"{folder}{files[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels1 = meta_1.column_names_to_labels\n",
    "value_labels1 = meta_1.variable_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels2 = meta_2.column_names_to_labels\n",
    "value_labels2 = meta_2.variable_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels3 = meta_3.column_names_to_labels\n",
    "value_labels3 = meta_3.variable_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID1             HHID              CASEID  V001  V002  V003  V004  \\\n",
      "0  2019.0        000100201        000100201  2   1.0   2.0   2.0   1.0   \n",
      "1  2019.0        000100201        000100201  3   1.0   2.0   3.0   1.0   \n",
      "2  2019.0        000102801        000102801  2   1.0  28.0   2.0   1.0   \n",
      "3  2019.0        000102801        000102801  6   1.0  28.0   6.0   1.0   \n",
      "4  2019.0        000104801        000104801  2   1.0  48.0   2.0   1.0   \n",
      "\n",
      "     V007    V008  V009  ...  QD333_4  QD333_5  QD333_6  UBIGEO  V022  \\\n",
      "0  2019.0  1434.0   4.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "1  2019.0  1434.0   1.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "2  2019.0  1434.0   6.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "3  2019.0  1434.0   3.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "4  2019.0  1434.0   5.0  ...      2.0      2.0      2.0  010101   3.0   \n",
      "\n",
      "       V005  V190      V191  mujeres12a49  NCONGLOME  \n",
      "0  154803.0   4.0  1.234450           2.0     7065.0  \n",
      "1  154803.0   4.0  1.234450           0.0     7065.0  \n",
      "2  154803.0   4.0  1.295611           2.0     7065.0  \n",
      "3  154803.0   4.0  1.295611           2.0     7065.0  \n",
      "4  154803.0   2.0 -0.256431           2.0     7065.0  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "      ID1              CASEID  V201  V202  V203  V204  V205  V206  V207  V208  \\\n",
      "0  2019.0        000100201  2   2.0   1.0   1.0   0.0   0.0   0.0   0.0   1.0   \n",
      "1  2019.0        000100201  3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2  2019.0        000102801  2   3.0   1.0   2.0   0.0   0.0   0.0   0.0   2.0   \n",
      "3  2019.0        000102801  6   3.0   1.0   0.0   2.0   0.0   0.0   0.0   0.0   \n",
      "4  2019.0        000104801  2   3.0   1.0   2.0   0.0   0.0   0.0   0.0   1.0   \n",
      "\n",
      "   ...  V307_09  V307_10  V307_11  V307_12  V307_13  V307_14  V307_15  \\\n",
      "0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2  ...      0.0      0.0      NaN      NaN      NaN      NaN      NaN   \n",
      "3  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "   V307_16  QI302_05A  QI302_05B  \n",
      "0      0.0        1.0        2.0  \n",
      "1      NaN        NaN        NaN  \n",
      "2      0.0        2.0        1.0  \n",
      "3      NaN        2.0        2.0  \n",
      "4      NaN        2.0        1.0  \n",
      "\n",
      "[5 rows x 176 columns]\n",
      "      ID1              CASEID  V501  V502  V503  V504  V505  V506  V507  \\\n",
      "0  2019.0        000100201  2   1.0   1.0   1.0   1.0   NaN   NaN   1.0   \n",
      "1  2019.0        000102801  2   2.0   1.0   1.0   1.0   NaN   NaN  12.0   \n",
      "2  2019.0        000102801  6   5.0   2.0   1.0   NaN   NaN   NaN   8.0   \n",
      "3  2019.0        000104801  2   2.0   1.0   1.0   1.0   NaN   NaN  12.0   \n",
      "4  2019.0        000113601  2   2.0   1.0   2.0   1.0   NaN   NaN  12.0   \n",
      "\n",
      "     V508  ...  V743C  V743D  V743E  V743F  V744A  V744B  V744C  V744D  V744E  \\\n",
      "0  2008.0  ...    1.0    2.0    1.0    4.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1  2011.0  ...    2.0    1.0    1.0    2.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2  1984.0  ...    NaN    NaN    NaN    NaN    0.0    0.0    0.0    0.0    0.0   \n",
      "3  2009.0  ...    1.0    1.0    1.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4  2005.0  ...    1.0    1.0    2.0    4.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   V746  \n",
      "0   1.0  \n",
      "1   2.0  \n",
      "2   NaN  \n",
      "3   NaN  \n",
      "4   2.0  \n",
      "\n",
      "[5 rows x 84 columns]\n"
     ]
    }
   ],
   "source": [
    "print(rec_1.head())\n",
    "print(rec_2.head())\n",
    "print(rec_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we start by shortening the term \"pandas\" to \"pd\" while preparing the \"import pyreadstat\" command in order to work with SCSS files in Pandas. Then, we just choose to \"folder\" and \"files\" as variables of the directory and the 3 main files respectively. After this, it is time to import and change the name of files. With this ready, we need to generate new variables (\"var_labels#\" and \"value_labels#\") and assign the content of them. That is all for the step 1, the use of print to the recs variables is only for verification issues. In adittion, the use of \".head\" is to show only a little part of the DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1 = rec_1[columns_rec1].copy()\n",
    "rec2_1 = rec_2[columns_rec2].copy()\n",
    "rec3_1 = rec_3[columns_rec3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_labels1 = {col: var_labels1.get(col, \"\") for col in columns_rec1}\n",
    "new_var_labels2 = {col: var_labels2.get(col, \"\") for col in columns_rec2}\n",
    "new_var_labels3 = {col: var_labels3.get(col, \"\") for col in columns_rec3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value_labels1 = {col: value_labels1.get(col, {}) for col in columns_rec1}\n",
    "new_value_labels2 = {col: value_labels2.get(col, {}) for col in columns_rec2}\n",
    "new_value_labels3 = {col: value_labels3.get(col, {}) for col in columns_rec3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1rst step: create variables type \"columns_rec#\" to insert every data in his respective group. 2nd step: create standalone copys (dataframes) of the previous variables and called them as rec#_ #.  3nd step: Create  new variable and value labels through of \"col\" and \".get\" to preservate the original version even if the new variables are modified. In addition, it is relevant to mention these dictionaries contain only main columns of every correpondent data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1.loc[:, 'year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_labels1.update({'year': 'Year of the survey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1rst step: Generate the new column \"year\" through the \".loc\" method (you just need to write \"year\" and since it is not there, it will be added automatically) . 2nd step: Update the dictionary adding \"Year of the survey\" by means of the \"year\" key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Get the min, max, sd, n_obs, n_missing for the following columns **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)**. We want a dataframe with the following columns **Variables, Min, Max, Mean, N_obs, N_missing** and sort by the number of missing rows. **Hint: Use `describe` and `pivot` methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `endes_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Reshape `mean_key_vars` from wide to long. We want a dataframe with three columns **dpto, variables, values**. Name this object as `reshape_mean_key_vars`. **Hint: Use melt method**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Replicate your answers for questions 7 and 8, but in one line of code. Make it the most simple as possible. **NO HINT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `reshape_mean_key_vars` with `endes_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

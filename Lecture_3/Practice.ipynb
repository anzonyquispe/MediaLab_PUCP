{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605c783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c44c47",
   "metadata": {},
   "source": [
    "1. We have data `MotherData.csv` excerpted from a recent Demographic and Health Survey.  First convert the dataset from `wide` (each observation is a mother) to `long` (each observation is a birth, with associated mother id). The id `caseid` identifies uniquely all the mothers.  These columns refer to variable of children **['bidx', 'bord', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9', 'b10', 'b11', 'b12', 'b13', 'b15', 'b16']** and have new columns for all their children. We have information for 20 children. It starts from last child to oldest one. Use for loops to reshape this dataset from `wide` to `long` ate mother and children level. If you want to get more information from the columns please see [this pdf](http://www.dhsprogram.com/pubs/pdf/DHSG4/Recode6_DHS_22March2013_DHSG4.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9691aa2",
   "metadata": {},
   "source": [
    "\n",
    "# Reshaping Data from Wide to Long Format in Python\n",
    "\n",
    "## Understanding the Task\n",
    "\n",
    "1. **Dataset Structure**: The dataset in the wide format has each row representing a mother, with multiple columns for each child.\n",
    "2. **Objective**: Convert this dataset to a long format where each row represents a child, including the mother's ID.\n",
    "\n",
    "## Analyzing the Provided Code\n",
    "\n",
    "- Import the dataset and prepare an array to iterate through children.\n",
    "- Use a for loop to handle each child, selecting relevant columns and creating a DataFrame for each.\n",
    "- Concatenate these DataFrames to create a long format dataset.\n",
    "\n",
    "## Suggestions and Instructions for Completion\n",
    "\n",
    "### Understanding the Code\n",
    "\n",
    "- Explain the purpose of each line, e.g., `nchilds_list` creates a formatted list of child indices for column naming.\n",
    "- Discuss the use of `map` and string formatting in `lambda x: x + f\"_{childx}\"`.\n",
    "\n",
    "### Modify Column Renaming\n",
    "\n",
    "- Ensure understanding of `df1.columns = ['caseid'] +  prefixes` for aligning columns to a standard format after each loop iteration.\n",
    "\n",
    "### Avoiding Duplicates\n",
    "\n",
    "- Teach filtering out rows where data for a specific child does not exist, useful when a mother has fewer than 20 children.\n",
    "\n",
    "### Adding a Child Identifier\n",
    "\n",
    "- Add a column indicating the child's number in each loop iteration:\n",
    "\n",
    "  ```python\n",
    "  for childx in nchilds_list:\n",
    "      cols = ['caseid'] + list(map(lambda x: x + f\"_{childx}\", prefixes))\n",
    "      df1 = df.loc[:, cols].copy()\n",
    "      df1.columns = ['caseid'] + prefixes\n",
    "      df1['child_number'] = childx  # Adding child number\n",
    "      append_df.append(df1)\n",
    "  ```\n",
    "\n",
    "### Handling Missing Data\n",
    "\n",
    "- Handle missing data which might arise if some mothers have fewer than 20 children.\n",
    "\n",
    "### Code Testing and Validation\n",
    "\n",
    "- Test with a small subset first and validate the long-format DataFrame's structure and sample rows.\n",
    "\n",
    "### Encourage Exploration\n",
    "\n",
    "- Try different approaches, like more advanced pandas functions or performing the task without a loop.\n",
    "\n",
    "### Commenting and Documentation\n",
    "\n",
    "- Stress the importance of commenting on the code for better understanding.\n",
    "\n",
    "### Consulting Documentation and Resources\n",
    "\n",
    "- Refer to the pandas documentation for unfamiliar functions.\n",
    "\n",
    "## Example: Adding Child Identifier\n",
    "\n",
    "```python\n",
    "for childx in nchilds_list:\n",
    "    cols = ['caseid'] + list(map(lambda x: x + f\"_{childx}\", prefixes))\n",
    "    df1 = df.loc[:, cols].copy()\n",
    "    df1.columns = ['caseid'] + prefixes\n",
    "    df1['child_number'] = childx  # Adding child number\n",
    "    append_df.append(df1)\n",
    "```\n",
    "\n",
    "## Final Steps\n",
    "\n",
    "- Check the resulting DataFrame's head and tail.\n",
    "- Perform necessary cleaning or filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac826ef",
   "metadata": {},
   "source": [
    "2. Import all the RECH1.SAV files from all the subfolder located in this folder. `Diplomado_PUCP/_data/endes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25b685",
   "metadata": {},
   "source": [
    "Step 1: Understanding the File Structure\n",
    "Your task is to navigate through the directory Diplomado_PUCP/_data/endes and its subdirectories.\n",
    "You need to find files named RECH1.SAV in these subdirectories.\n",
    "\n",
    "Step 2: Importing Necessary Libraries\n",
    "Before writing the script, you need to import some essential libraries. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f30b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fab2640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a015ea08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2016, 2017, 2018, 2019])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2015, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c34516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015 = pd.read_spss('/Users/ar8787/Documents/GitHub/Diplomado_PUCP/_data/endes/2015/RECH1.SAV')\n",
    "\n",
    "df2015['year_sample'] = 2015\n",
    "\n",
    "df2016 = pd.read_spss('/Users/ar8787/Documents/GitHub/Diplomado_PUCP/_data/endes/2016/RECH1.SAV')\n",
    "\n",
    "df2016['year_sample'] = 2016\n",
    "\n",
    "df2017 = pd.read_spss('/Users/ar8787/Documents/GitHub/Diplomado_PUCP/_data/endes/2017/RECH1.SAV')\n",
    "\n",
    "df2017['year_sample'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e36bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "years = np.arange(2015, 2020)\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f'/Users/ar8787/Documents/GitHub/Diplomado_PUCP/_data/endes/{year}/RECH1.SAV'\n",
    "    df = pd.read_spss(file_path)\n",
    "    df['year_sample'] = year\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames for different years into a single DataFrame\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b00b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHID</th>\n",
       "      <th>HVIDX</th>\n",
       "      <th>HV101</th>\n",
       "      <th>HV102</th>\n",
       "      <th>HV103</th>\n",
       "      <th>HV104</th>\n",
       "      <th>HV105</th>\n",
       "      <th>HV106</th>\n",
       "      <th>HV107</th>\n",
       "      <th>HV108</th>\n",
       "      <th>...</th>\n",
       "      <th>QH13A4</th>\n",
       "      <th>QH13A5</th>\n",
       "      <th>QH13A6</th>\n",
       "      <th>year_sample</th>\n",
       "      <th>QH25A</th>\n",
       "      <th>QH25B</th>\n",
       "      <th>QH25CM</th>\n",
       "      <th>QH25CA</th>\n",
       "      <th>QH21A</th>\n",
       "      <th>ID1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000104301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000207901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000211901</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000213001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000218601</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724981</th>\n",
       "      <td>325407201</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hijo/Hija</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Primario</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>PERUANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724982</th>\n",
       "      <td>325407301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jefe del Hogar</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Superior</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>PERUANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724983</th>\n",
       "      <td>325407401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jefe del Hogar</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Secundario</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>PERUANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724984</th>\n",
       "      <td>325407401</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Esposa o esposo</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Secundario</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>PERUANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724985</th>\n",
       "      <td>325407401</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hijo/Hija</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Sí</td>\n",
       "      <td>Hombre</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sin educación, preescolar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>PERUANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724986 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HHID  HVIDX            HV101 HV102 HV103   HV104 HV105  \\\n",
       "0             000104301    3.0     Son/daughter   Yes   Yes    Male   2.0   \n",
       "1             000207901    5.0     Son/daughter   Yes   Yes    Male   0.0   \n",
       "2             000211901    4.0     Son/daughter   Yes   Yes    Male   3.0   \n",
       "3             000213001    5.0   Other relative   Yes   Yes    Male   2.0   \n",
       "4             000218601    2.0     Son/daughter   Yes   Yes    Male   3.0   \n",
       "...                 ...    ...              ...   ...   ...     ...   ...   \n",
       "724981        325407201    3.0        Hijo/Hija    Sí    Sí  Hombre   9.0   \n",
       "724982        325407301    1.0   Jefe del Hogar    Sí    Sí  Hombre  35.0   \n",
       "724983        325407401    1.0   Jefe del Hogar    Sí    Sí  Hombre  24.0   \n",
       "724984        325407401    2.0  Esposa o esposo    Sí    Sí   Mujer  23.0   \n",
       "724985        325407401    3.0        Hijo/Hija    Sí    Sí  Hombre   4.0   \n",
       "\n",
       "                            HV106 HV107 HV108  ... QH13A4 QH13A5 QH13A6  \\\n",
       "0         No education, preschool   NaN   0.0  ...     No     No     No   \n",
       "1         No education, preschool   NaN   0.0  ...     No     No     No   \n",
       "2         No education, preschool   NaN   0.0  ...     No     No     No   \n",
       "3         No education, preschool   NaN   0.0  ...     No     No     No   \n",
       "4         No education, preschool   NaN   0.0  ...     No     No     No   \n",
       "...                           ...   ...   ...  ...    ...    ...    ...   \n",
       "724981                   Primario   3.0   3.0  ...    NaN    NaN    NaN   \n",
       "724982                   Superior   2.0  13.0  ...    NaN    NaN    NaN   \n",
       "724983                 Secundario   5.0  11.0  ...    NaN    NaN    NaN   \n",
       "724984                 Secundario   3.0   9.0  ...    NaN    NaN    NaN   \n",
       "724985  Sin educación, preescolar   NaN   0.0  ...    NaN    NaN    NaN   \n",
       "\n",
       "       year_sample    QH25A QH25B QH25CM QH25CA QH21A     ID1  \n",
       "0             2015      NaN   NaN    NaN    NaN   NaN     NaN  \n",
       "1             2015      NaN   NaN    NaN    NaN   NaN     NaN  \n",
       "2             2015      NaN   NaN    NaN    NaN   NaN     NaN  \n",
       "3             2015      NaN   NaN    NaN    NaN   NaN     NaN  \n",
       "4             2015      NaN   NaN    NaN    NaN   NaN     NaN  \n",
       "...            ...      ...   ...    ...    ...   ...     ...  \n",
       "724981        2019  PERUANA   NaN    NaN    NaN    No  2019.0  \n",
       "724982        2019  PERUANA   NaN    NaN    NaN   NaN  2019.0  \n",
       "724983        2019  PERUANA   NaN    NaN    NaN   NaN  2019.0  \n",
       "724984        2019  PERUANA   NaN    NaN    NaN   NaN  2019.0  \n",
       "724985        2019  PERUANA   NaN    NaN    NaN    No  2019.0  \n",
       "\n",
       "[724986 rows x 54 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data\n",
    "df_app = pd.concat([df2015, df2016, df2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f2da76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHID</th>\n",
       "      <th>HVIDX</th>\n",
       "      <th>HV101</th>\n",
       "      <th>HV102</th>\n",
       "      <th>HV103</th>\n",
       "      <th>HV104</th>\n",
       "      <th>HV105</th>\n",
       "      <th>HV106</th>\n",
       "      <th>HV107</th>\n",
       "      <th>HV108</th>\n",
       "      <th>...</th>\n",
       "      <th>HV138</th>\n",
       "      <th>HV139</th>\n",
       "      <th>HV140</th>\n",
       "      <th>QH13A1</th>\n",
       "      <th>QH13A2</th>\n",
       "      <th>QH13A3</th>\n",
       "      <th>QH13A4</th>\n",
       "      <th>QH13A5</th>\n",
       "      <th>QH13A6</th>\n",
       "      <th>year_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000104301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000207901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000211901</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000213001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000218601</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140593</th>\n",
       "      <td>317510701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Head</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Primary</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140594</th>\n",
       "      <td>317510701</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wife or husband</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140595</th>\n",
       "      <td>317510701</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140596</th>\n",
       "      <td>317510701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140597</th>\n",
       "      <td>317510701</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No education, preschool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433871 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   HHID  HVIDX            HV101 HV102 HV103   HV104 HV105  \\\n",
       "0             000104301    3.0     Son/daughter   Yes   Yes    Male   2.0   \n",
       "1             000207901    5.0     Son/daughter   Yes   Yes    Male   0.0   \n",
       "2             000211901    4.0     Son/daughter   Yes   Yes    Male   3.0   \n",
       "3             000213001    5.0   Other relative   Yes   Yes    Male   2.0   \n",
       "4             000218601    2.0     Son/daughter   Yes   Yes    Male   3.0   \n",
       "...                 ...    ...              ...   ...   ...     ...   ...   \n",
       "140593        317510701    1.0             Head   Yes   Yes    Male  31.0   \n",
       "140594        317510701    2.0  Wife or husband   Yes   Yes  Female  29.0   \n",
       "140595        317510701    3.0     Son/daughter   Yes   Yes    Male   5.0   \n",
       "140596        317510701    4.0     Son/daughter   Yes   Yes  Female   4.0   \n",
       "140597        317510701    5.0     Son/daughter   Yes   Yes  Female   0.0   \n",
       "\n",
       "                          HV106 HV107 HV108  ... HV138 HV139 HV140 QH13A1  \\\n",
       "0       No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "1       No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "2       No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "3       No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "4       No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "...                         ...   ...   ...  ...   ...   ...   ...    ...   \n",
       "140593                  Primary   5.0   5.0  ...   NaN   NaN   NaN     No   \n",
       "140594  No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "140595  No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "140596  No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "140597  No education, preschool   NaN   0.0  ...   NaN   NaN   NaN     No   \n",
       "\n",
       "       QH13A2 QH13A3 QH13A4 QH13A5 QH13A6 year_sample  \n",
       "0          No     No     No     No     No        2015  \n",
       "1          No     No     No     No     No        2015  \n",
       "2          No     No     No     No     No        2015  \n",
       "3          No     No     No     No     No        2015  \n",
       "4          No     No     No     No     No        2015  \n",
       "...       ...    ...    ...    ...    ...         ...  \n",
       "140593     No     No     No     No     No        2017  \n",
       "140594     No     No     No     No     No        2017  \n",
       "140595     No     No     No     No     No        2017  \n",
       "140596     No     No     No     No     No        2017  \n",
       "140597     No     No     No     No     No        2017  \n",
       "\n",
       "[433871 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd808300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2678e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "# If you need to read .SAV files, you might need a library like pyreadstat\n",
    "import pyreadstat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11a1f2",
   "metadata": {},
   "source": [
    "Step 3: Navigating Directories and Finding Files\n",
    "You can use os and glob libraries to navigate through directories and find files. Here's a basic way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sav_files(base_path):\n",
    "    # This pattern will match any RECH1.SAV files in subdirectories of the base path\n",
    "    pattern = os.path.join(base_path, '**', 'RECH1.SAV')\n",
    "    \n",
    "    # glob.glob will return a list of file paths matching the pattern\n",
    "    # recursive=True allows searching in subdirectories\n",
    "    return glob.glob(pattern, recursive=True)\n",
    "\n",
    "base_path = 'Diplomado_PUCP/_data/endes'\n",
    "sav_files = find_sav_files(base_path)\n",
    "print(\"Found .SAV files:\", sav_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec2bd4",
   "metadata": {},
   "source": [
    "Step 4: Reading .SAV Files\n",
    "If you need to read data from these .SAV files, you can use pyreadstat. Here's a simple way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aece45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sav_file(file_path):\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "    return df  # df is a DataFrame containing the data from the .SAV file\n",
    "\n",
    "# Example of reading the first found .SAV file\n",
    "if sav_files:\n",
    "    first_file_data = read_sav_file(sav_files[0])\n",
    "    print(first_file_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36dbd11",
   "metadata": {},
   "source": [
    "Step 5: Additional Suggestions\n",
    "Handling Exceptions: It's a good practice to handle exceptions, like file not found or read errors.\n",
    "Learning Resources: Encourage students to refer to Python documentation or tutorials for understanding libraries like os, glob, and pyreadstat.\n",
    "Code Comments: Teach them to write comments to explain their code for better understanding.\n",
    "Practice: Encourage them to modify the script, like reading specific columns or data processing, to get more practice.\n",
    "\n",
    "\n",
    "Step 6: Encouragement and Patience\n",
    "Remind the students that learning to code takes time and practice. Encourage them to experiment with the code and explore additional Python features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
